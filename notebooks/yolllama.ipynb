{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7361d598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing 3 images with 0.3-seconds delay...\n",
      "Captured frame 1\n",
      "Captured frame 2\n",
      "Captured frame 3\n",
      "Running YOLO inference on each frame...\n",
      "\n",
      "0: 384x640 (no detections), 35.9ms\n",
      "Speed: 2.2ms preprocess, 35.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 adidas_samba, 31.1ms\n",
      "Speed: 1.6ms preprocess, 31.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 adidas_samba, 29.8ms\n",
      "Speed: 1.6ms preprocess, 29.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Sending prompt to Ollama...\n",
      "\n",
      "LLM Response:\n",
      "\n",
      "You look like you're going for a casual and comfortable vibe with that dark t-shirt! It's a great choice to pair with just about anything. I would suggest pairing it with some distressed denim jeans or black leggings for a relaxed, weekend look.\n",
      "\n",
      "Alternatively, if you want to dress up the outfit, you could add a blazer or a cardigan to give it a more polished feel. And don't forget to add some sneakers or loafers to complete the casual-chic look!\n",
      "\n",
      "How do those suggestions sound?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO('/Users/maximilian/Documents/Macbook Air 13/Studium/projects/wardrobe_detection_yolo/outputs/models/yolov8n_finetuned.pt')\n",
    "\n",
    "# Correct label mapping\n",
    "correct_names = [\n",
    "    'adidas_samba',\n",
    "    'adidas_spezial',\n",
    "    'nike_killshot',\n",
    "    'pants_dark',\n",
    "    'pants_light',\n",
    "    'shirt_lightblue',\n",
    "    'shirt_lightlinen',\n",
    "    'tshirt_dark',\n",
    "    'tshirt_white'\n",
    "]\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(1)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "frames = []\n",
    "\n",
    "print(\"Capturing 3 images with 0.3-seconds delay...\")\n",
    "for i in range(3):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frames.append(frame)\n",
    "        print(f\"Captured frame {i+1}\")\n",
    "    else:\n",
    "        print(f\"Failed to capture frame {i+1}\")\n",
    "    time.sleep(0.3)  # 0.3-seconds delay between captures\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Aggregate detections\n",
    "label_stats = defaultdict(list)\n",
    "\n",
    "print(\"Running YOLO inference on each frame...\")\n",
    "for frame in frames:\n",
    "    results = model.predict(frame, show=False)[0]\n",
    "    results.names = correct_names\n",
    "\n",
    "    for box in results.boxes:\n",
    "        class_id = int(box.cls[0])\n",
    "        label = results.names[class_id]\n",
    "        confidence = float(box.conf[0])\n",
    "        label_stats[label].append(confidence)\n",
    "\n",
    "# Compute average confidence\n",
    "aggregated = {label: sum(confs) / len(confs) for label, confs in label_stats.items()}\n",
    "\n",
    "# Build LLM prompt\n",
    "prompt_context = \"Objects detected across multiple frames:\\n\"\n",
    "for label, avg_conf in aggregated.items():\n",
    "    prompt_context += f\"- {label} (avg confidence: {avg_conf:.2f})\\n\"\n",
    "\n",
    "full_prompt = f\"\"\"\n",
    "You are a wardrobe assistant. Based on the items detected, give outfit advice or a compliment.\n",
    "\n",
    "{prompt_context}\n",
    "\"\"\"\n",
    "\n",
    "# Query Ollama via subprocess\n",
    "def query_ollama(prompt, model='llama3.2:latest'):\n",
    "    result = subprocess.run(\n",
    "        ['ollama', 'run', model],\n",
    "        input=prompt.encode('utf-8'),\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "    return result.stdout.decode('utf-8')\n",
    "\n",
    "# Run and display LLM output\n",
    "print(\"Sending prompt to Ollama...\")\n",
    "response = query_ollama(full_prompt)\n",
    "print(\"\\nLLM Response:\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b015c9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 23:48:22.262 Python[80137:967805] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing 3 images with 0.3-second delay...\n",
      "Captured frame 1\n",
      "Captured frame 2\n",
      "Captured frame 3\n",
      "Running YOLO inference on each frame...\n",
      "\n",
      "0: 384x640 (no detections), 32.6ms\n",
      "Speed: 2.0ms preprocess, 32.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 adidas_samba, 33.4ms\n",
      "Speed: 1.6ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 adidas_samba, 33.0ms\n",
      "Speed: 1.5ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "LLM Response:\n",
      "\n",
      "You have a versatile and comfortable base layer with your dark T-shirt! I'd recommend pairing it with some versatile bottoms to create a stylish outfit.\n",
      "\n",
      "How about trying a pair of distressed denim jeans or a flowy black skirt to add some visual interest? You could also consider adding a statement jacket, like a leather biker jacket or a denim jacket with embroidery, to give your outfit a cool edge.\n",
      "\n",
      "If you want to keep things simple, you could stick with the T-shirt and add a pair of sneakers, ankle boots, or even sandals for a more relaxed vibe. Whatever you choose, I'm sure you'll look great!"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO('/Users/maximilian/Documents/Macbook Air 13/Studium/projects/wardrobe_detection_yolo/outputs/models/yolov8n_finetuned.pt')\n",
    "\n",
    "# Correct label mapping\n",
    "correct_names = [\n",
    "    'adidas_samba',\n",
    "    'adidas_spezial',\n",
    "    'nike_killshot',\n",
    "    'pants_dark',\n",
    "    'pants_light',\n",
    "    'shirt_lightblue',\n",
    "    'shirt_lightlinen',\n",
    "    'tshirt_dark',\n",
    "    'tshirt_white'\n",
    "]\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(1)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "frames = []\n",
    "\n",
    "print(\"Capturing 3 images with 0.3-second delay...\")\n",
    "for i in range(3):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frames.append(frame)\n",
    "        print(f\"Captured frame {i+1}\")\n",
    "    else:\n",
    "        print(f\"Failed to capture frame {i+1}\")\n",
    "    time.sleep(0.3)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Aggregate detections\n",
    "label_stats = defaultdict(list)\n",
    "\n",
    "print(\"Running YOLO inference on each frame...\")\n",
    "for frame in frames:\n",
    "    results = model.predict(frame, show=False)[0]\n",
    "    results.names = correct_names\n",
    "\n",
    "    for box in results.boxes:\n",
    "        class_id = int(box.cls[0])\n",
    "        label = results.names[class_id]\n",
    "        confidence = float(box.conf[0])\n",
    "        label_stats[label].append(confidence)\n",
    "\n",
    "# Compute average confidence\n",
    "aggregated = {label: sum(confs) / len(confs) for label, confs in label_stats.items()}\n",
    "\n",
    "prompt_prefix = \"\"\"You are a helpful wardrobe assistant.\n",
    "\n",
    "Your job is to give supportive, casual outfit advice or compliments based on detected clothing items.\n",
    "\n",
    "Here are some examples of how you might respond:\n",
    "- \"Nice combo! The white tee and light pants make for a clean summer look.\"\n",
    "- \"That's a great casual fit â€” especially those Adidas Spezial shoes.\"\n",
    "- \"Perfect for a relaxed day. You could throw on a jacket if it's chilly.\"\n",
    "\n",
    "Now here's the input:\n",
    "\"\"\"\n",
    "\n",
    "# Build prompt\n",
    "detected_context = \"Objects detected across multiple frames:\\n\"\n",
    "for label, avg_conf in aggregated.items():\n",
    "    detected_context += f\"- {label} (avg confidence: {avg_conf:.2f})\\n\"\n",
    "\n",
    "full_prompt = prompt_prefix + detected_context\n",
    "\n",
    "def stream_ollama(prompt, model='llama3.2'):\n",
    "    url = 'http://localhost:11434/api/generate'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    payload = {\n",
    "        'model': model,\n",
    "        'prompt': prompt,\n",
    "        'stream': True\n",
    "    }\n",
    "\n",
    "    print(\"\\nLLM Response:\\n\")\n",
    "    response = requests.post(url, json=payload, stream=True)\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            try:\n",
    "                data = json.loads(line.decode('utf-8'))\n",
    "                print(data.get(\"response\", \"\"), end='', flush=True)\n",
    "            except json.JSONDecodeError:\n",
    "                continue  # skip bad lines silently\n",
    "\n",
    "# Run streaming query\n",
    "stream_ollama(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e4a6a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Capturing your outfit...\n",
      "\n",
      "0: 384x640 (no detections), 33.8ms\n",
      "Speed: 1.3ms preprocess, 33.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.3ms\n",
      "Speed: 1.5ms preprocess, 34.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 adidas_samba, 31.3ms\n",
      "Speed: 1.4ms preprocess, 31.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "LLM Response:\n",
      "\n",
      "Input:\n",
      "- tshirt_dark (confidence: 0.51)\n",
      "\n",
      "User: How do I look?\n",
      "\n",
      "Output:\n",
      "Honestly, it's a bit of an understated look for you. Why not add some depth with a statement piece like a patterned scarf or a bold necklace to elevate your dark tee?\n",
      "\n",
      "Step 2: Capturing updated outfit (e.g. changed something)...\n",
      "\n",
      "0: 384x640 (no detections), 34.1ms\n",
      "Speed: 1.3ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.5ms preprocess, 32.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 adidas_samba, 33.7ms\n",
      "Speed: 1.4ms preprocess, 33.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "LLM Response:\n",
      "\n",
      "That's great taste in tees! The dark color is really versatile and can be dressed up or down. To take it from casual to cool, consider pairing it with some distressed denim jeans or a pair of sleek sneakers to add some edge to your look."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ------------------ CONFIG ------------------ #\n",
    "\n",
    "# YOLO model path and label map\n",
    "model = YOLO('/Users/maximilian/Documents/Macbook Air 13/Studium/projects/wardrobe_detection_yolo/outputs/models/yolov8n_finetuned.pt')\n",
    "correct_names = [\n",
    "    'adidas_samba', 'adidas_spezial', 'nike_killshot',\n",
    "    'pants_dark', 'pants_light',\n",
    "    'shirt_lightblue', 'shirt_lightlinen',\n",
    "    'tshirt_dark', 'tshirt_white'\n",
    "]\n",
    "\n",
    "# Prompt prefix (constant)\n",
    "prompt_prefix = \"\"\"You are a wardrobe assistant. Give a friendly compliment or fashion tip based on the detected outfit and user request.\n",
    "\n",
    "Example:\n",
    "Input:\n",
    "- tshirt_white (confidence: 0.91)\n",
    "- pants_light (confidence: 0.88)\n",
    "User: What should I wear if I go out tonight?\n",
    "\n",
    "Output:\n",
    "That's a clean combo. You could throw on a bomber jacket or denim to add some personality.\n",
    "\n",
    "---\n",
    "\n",
    "Now your turn:\n",
    "\"\"\"\n",
    "\n",
    "# ------------------ FUNCTIONS ------------------ #\n",
    "\n",
    "def capture_frames(n=3, delay=0.):\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Could not open webcam.\")\n",
    "    frames = []\n",
    "    for i in range(n):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(frame)\n",
    "        time.sleep(delay)\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def detect_clothing(frames):\n",
    "    label_stats = defaultdict(list)\n",
    "    for frame in frames:\n",
    "        results = model.predict(frame, show=False)[0]\n",
    "        results.names = correct_names\n",
    "        for box in results.boxes:\n",
    "            class_id = int(box.cls[0])\n",
    "            label = results.names[class_id]\n",
    "            confidence = float(box.conf[0])\n",
    "            label_stats[label].append(confidence)\n",
    "    aggregated = {label: sum(c) / len(c) for label, c in label_stats.items()}\n",
    "    return aggregated\n",
    "\n",
    "def build_prompt(aggregated, user_input):\n",
    "    detected = '\\n'.join(f\"- {label} (confidence: {conf:.2f})\" for label, conf in aggregated.items())\n",
    "    return f\"{prompt_prefix}Input:\\n{detected}\\nUser: {user_input}\\nOutput:\"\n",
    "\n",
    "def query_ollama_stream(prompt, model='llama3.2'):\n",
    "    url = 'http://localhost:11434/api/generate'\n",
    "    payload = {'model': model, 'prompt': prompt, 'stream': True}\n",
    "    print(\"\\nLLM Response:\\n\")\n",
    "    response = requests.post(url, json=payload, stream=True)\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            try:\n",
    "                data = json.loads(line.decode('utf-8'))\n",
    "                print(data.get(\"response\", \"\"), end='', flush=True)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "# ------------------ INTERACTION ------------------ #\n",
    "\n",
    "# Round 1: Detect + Prompt\n",
    "print(\"Step 1: Capturing your outfit...\")\n",
    "frames = capture_frames()\n",
    "aggregated = detect_clothing(frames)\n",
    "\n",
    "user_input = input(\"\\nWhat do you want to ask or say to the mirror assistant? (e.g., 'Is this good for a date?')\\n> \")\n",
    "full_prompt = build_prompt(aggregated, user_input)\n",
    "query_ollama_stream(full_prompt)\n",
    "\n",
    "# Round 2: New detection + Prompt\n",
    "print(\"\\n\\nStep 2: Capturing updated outfit (e.g. changed something)...\")\n",
    "frames = capture_frames()\n",
    "aggregated = detect_clothing(frames)\n",
    "\n",
    "user_input = input(\"\\nAnything else you want to ask now?\\n> \")\n",
    "full_prompt = build_prompt(aggregated, user_input)\n",
    "query_ollama_stream(full_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
